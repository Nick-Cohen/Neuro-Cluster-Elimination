{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import FastGM\n",
    "from inference import FastFactor\n",
    "from sampling import SampleGenerator\n",
    "from inference import populate_gradient_factors\n",
    "from data import DataLoader\n",
    "from data import create_data_loaders\n",
    "from data import DataPreprocessor\n",
    "from neural_networks import Trainer\n",
    "from neural_networks.losses import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchinfo\n",
    "import torch.nn as nn\n",
    "from neural_networks import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyGMs.factor.Factor'>\n",
      "<class 'pyGMs.factor.Factor'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ib = 5\n",
    "Z = 303.0859680175781\n",
    "# uai_file = \"/home/cohenn1/SDBE/width_under_20_problems/grid10x10.f10.uai\"\n",
    "uai_file = \"/home/cohenn1/SDBE/width20-30/grid20x20.f2.uai\"\n",
    "# problem_name = \"grid10x10.f10-ib\" + str(ib)\n",
    "problem_name = \"grid20x20.f2-ib\" + str(ib)\n",
    "output_path = \"/home/cohenn1/SDBE/PyTorchGMs/graphs\"\n",
    "grid20f2_idxs = [30, 106, 213, 123, 331]\n",
    "# idx = 74 # for grid 20, ib10\n",
    "idx = 106\n",
    "#%%\n",
    "device = 'cuda'\n",
    "fastgm = FastGM(uai_file=uai_file, device=device)\n",
    "populate_gradient_factors(fastgm,iB=10)\n",
    "bucket=fastgm.buckets[idx]\n",
    "fastgm_copy = FastGM(uai_file=uai_file, device=device)\n",
    "mg, mess = fastgm.get_message_gradient(idx)\n",
    "gradient_factors = fastgm.get_gradient_factors(idx)\n",
    "mg_hat = fastgm_copy.get_wmb_message_gradient(bucket_var=idx, i_bound=ib, weights='max')\n",
    "mess.order_indices()\n",
    "mg_hat.order_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastgm.config = {\n",
    "    'num_samples': -1,\n",
    "    'sampling_scheme': 'all'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SampleGenerator(gm=fastgm, bucket=bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_assignments = sg.sample_assignments(1000)\n",
    "sample_values = sg.compute_message_values(sample_assignments)\n",
    "sample_mg_values = sg.compute_gradient_values(sample_assignments, [mg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preprocessor = DataPreprocessor(y=None, mg=None, is_logspace=True, device = device)\n",
    "data_preprocessor = DataPreprocessor(y=sample_values, mg=sample_mg_values, is_logspace=True, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(bucket=bucket, sample_generator=sg, data_preprocessor=data_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=dl.load_batches(10,5,mgh_factors=[mg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, mgh = data_preprocessor.convert_data()\n",
    "x = data_preprocessor.one_hot_encode(bucket, sample_assignments, lower_dim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the function linear to test learning\n",
    "# y = x @ torch.tensor(np.arange(10) - 4.5).float().to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine y and mghat for testing\n",
    "# y = y + mgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size=len(batches[0]['x'][0]), hidden_sizes=[100,100], use_gradient_values=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "config = {\n",
    "    'loss_fn': 'from_logspace_gil1c',\n",
    "    'optimizer': 'adam',\n",
    "    'learning_rate': 0.0000001,\n",
    "    'device': device,\n",
    "    'num_samples': 102400000,\n",
    "    'batch_size': 1024,\n",
    "    'num_epochs': 1,\n",
    "    'set_size': 1024000,\n",
    "    \n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 1/100, Epoch 1/1, Loss: -17.864173889160156\n",
      "Set 2/100, Epoch 1/1, Loss: -17.86559295654297\n",
      "Set 3/100, Epoch 1/1, Loss: -17.868091583251953\n",
      "Set 4/100, Epoch 1/1, Loss: -17.872154235839844\n",
      "Set 5/100, Epoch 1/1, Loss: -17.87765121459961\n",
      "Set 6/100, Epoch 1/1, Loss: -17.87726402282715\n",
      "Set 7/100, Epoch 1/1, Loss: -17.878446578979492\n",
      "Set 8/100, Epoch 1/1, Loss: -17.87786293029785\n",
      "Set 9/100, Epoch 1/1, Loss: -17.879337310791016\n",
      "Set 10/100, Epoch 1/1, Loss: -17.8792724609375\n",
      "Set 11/100, Epoch 1/1, Loss: -17.879133224487305\n",
      "Set 12/100, Epoch 1/1, Loss: -17.878812789916992\n",
      "Set 13/100, Epoch 1/1, Loss: -17.877517700195312\n",
      "Set 14/100, Epoch 1/1, Loss: -17.87850570678711\n",
      "Set 15/100, Epoch 1/1, Loss: -17.879817962646484\n",
      "Set 16/100, Epoch 1/1, Loss: -17.8796329498291\n",
      "Set 17/100, Epoch 1/1, Loss: -17.87922477722168\n",
      "Set 18/100, Epoch 1/1, Loss: -17.879322052001953\n",
      "Set 19/100, Epoch 1/1, Loss: -17.87926483154297\n",
      "Set 20/100, Epoch 1/1, Loss: -17.880456924438477\n",
      "Set 21/100, Epoch 1/1, Loss: -17.88035011291504\n",
      "Set 22/100, Epoch 1/1, Loss: -17.880107879638672\n",
      "Set 23/100, Epoch 1/1, Loss: -17.879344940185547\n",
      "Set 24/100, Epoch 1/1, Loss: -17.88033103942871\n",
      "Set 25/100, Epoch 1/1, Loss: -17.879695892333984\n",
      "Set 26/100, Epoch 1/1, Loss: -17.881067276000977\n",
      "Set 27/100, Epoch 1/1, Loss: -17.881059646606445\n",
      "Set 28/100, Epoch 1/1, Loss: -17.88121223449707\n",
      "Set 29/100, Epoch 1/1, Loss: -17.88175392150879\n",
      "Set 30/100, Epoch 1/1, Loss: -17.883071899414062\n",
      "Set 31/100, Epoch 1/1, Loss: -17.88438606262207\n",
      "Set 32/100, Epoch 1/1, Loss: -17.88448143005371\n",
      "Set 33/100, Epoch 1/1, Loss: -17.884849548339844\n",
      "Set 34/100, Epoch 1/1, Loss: -17.88572883605957\n",
      "Set 35/100, Epoch 1/1, Loss: -17.887521743774414\n",
      "Set 36/100, Epoch 1/1, Loss: -17.890914916992188\n",
      "Set 37/100, Epoch 1/1, Loss: -17.893543243408203\n",
      "Set 38/100, Epoch 1/1, Loss: -17.897357940673828\n",
      "Set 39/100, Epoch 1/1, Loss: -17.897687911987305\n",
      "Set 40/100, Epoch 1/1, Loss: -17.897825241088867\n",
      "Set 41/100, Epoch 1/1, Loss: -17.898223876953125\n",
      "Set 42/100, Epoch 1/1, Loss: -17.89917755126953\n",
      "Set 43/100, Epoch 1/1, Loss: -17.901042938232422\n",
      "Set 44/100, Epoch 1/1, Loss: -17.904273986816406\n",
      "Set 45/100, Epoch 1/1, Loss: -17.906810760498047\n",
      "Set 46/100, Epoch 1/1, Loss: -17.90704345703125\n",
      "Set 47/100, Epoch 1/1, Loss: -17.908674240112305\n",
      "Set 48/100, Epoch 1/1, Loss: -17.908700942993164\n",
      "Set 49/100, Epoch 1/1, Loss: -17.908750534057617\n",
      "Set 50/100, Epoch 1/1, Loss: -17.908843994140625\n",
      "Set 51/100, Epoch 1/1, Loss: -17.90909767150879\n",
      "Set 52/100, Epoch 1/1, Loss: -17.909713745117188\n",
      "Set 53/100, Epoch 1/1, Loss: -17.911035537719727\n",
      "Set 54/100, Epoch 1/1, Loss: -17.91347312927246\n",
      "Set 55/100, Epoch 1/1, Loss: -17.917648315429688\n",
      "Set 56/100, Epoch 1/1, Loss: -17.919710159301758\n",
      "Set 57/100, Epoch 1/1, Loss: -17.920652389526367\n",
      "Set 58/100, Epoch 1/1, Loss: -17.922863006591797\n",
      "Set 59/100, Epoch 1/1, Loss: -17.9247989654541\n",
      "Set 60/100, Epoch 1/1, Loss: -17.928024291992188\n",
      "Set 61/100, Epoch 1/1, Loss: -17.92927360534668\n",
      "Set 62/100, Epoch 1/1, Loss: -17.930084228515625\n",
      "Set 63/100, Epoch 1/1, Loss: -17.929832458496094\n",
      "Set 64/100, Epoch 1/1, Loss: -17.93102264404297\n",
      "Set 65/100, Epoch 1/1, Loss: -17.931751251220703\n",
      "Set 66/100, Epoch 1/1, Loss: -17.930307388305664\n",
      "Set 67/100, Epoch 1/1, Loss: -17.93075180053711\n",
      "Set 68/100, Epoch 1/1, Loss: -17.930641174316406\n",
      "Set 69/100, Epoch 1/1, Loss: -17.93022346496582\n",
      "Set 70/100, Epoch 1/1, Loss: -17.931377410888672\n",
      "Set 71/100, Epoch 1/1, Loss: -17.93202018737793\n",
      "Set 72/100, Epoch 1/1, Loss: -17.931020736694336\n",
      "Set 73/100, Epoch 1/1, Loss: -17.93115234375\n",
      "Set 74/100, Epoch 1/1, Loss: -17.931686401367188\n",
      "Set 75/100, Epoch 1/1, Loss: -17.932926177978516\n",
      "Set 76/100, Epoch 1/1, Loss: -17.932952880859375\n",
      "Set 77/100, Epoch 1/1, Loss: -17.93313980102539\n",
      "Set 78/100, Epoch 1/1, Loss: -17.933767318725586\n",
      "Set 79/100, Epoch 1/1, Loss: -17.935468673706055\n",
      "Set 80/100, Epoch 1/1, Loss: -17.93653106689453\n",
      "Set 81/100, Epoch 1/1, Loss: -17.936508178710938\n",
      "Set 82/100, Epoch 1/1, Loss: -17.93682861328125\n",
      "Set 83/100, Epoch 1/1, Loss: -17.9381103515625\n",
      "Set 84/100, Epoch 1/1, Loss: -17.938419342041016\n",
      "Set 85/100, Epoch 1/1, Loss: -17.93907356262207\n",
      "Set 86/100, Epoch 1/1, Loss: -17.938003540039062\n",
      "Set 87/100, Epoch 1/1, Loss: -17.937931060791016\n",
      "Set 88/100, Epoch 1/1, Loss: -17.937881469726562\n",
      "Set 89/100, Epoch 1/1, Loss: -17.93791961669922\n",
      "Set 90/100, Epoch 1/1, Loss: -17.938106536865234\n",
      "Set 91/100, Epoch 1/1, Loss: -17.93862533569336\n",
      "Set 92/100, Epoch 1/1, Loss: -17.93983268737793\n",
      "Set 93/100, Epoch 1/1, Loss: -17.939332962036133\n",
      "Set 94/100, Epoch 1/1, Loss: -17.938024520874023\n",
      "Set 95/100, Epoch 1/1, Loss: -17.939048767089844\n",
      "Set 96/100, Epoch 1/1, Loss: -17.93967056274414\n",
      "Set 97/100, Epoch 1/1, Loss: -17.938358306884766\n",
      "Set 98/100, Epoch 1/1, Loss: -17.939456939697266\n",
      "Set 99/100, Epoch 1/1, Loss: -17.940269470214844\n",
      "Set 100/100, Epoch 1/1, Loss: -17.93992042541504\n"
     ]
    }
   ],
   "source": [
    "t=Trainer(net, dataloader=dl, config=config)\n",
    "t.train([mg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = Trainer(net, dataloader=None, config=config)\n",
    "# t.train_epoch(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# do_grad = config['loss_fn'] not in ['mse', 'l1', 'logspace_mse', 'from_logspace_l1', 'from_logspace_mse', 'logspace_l1']\n",
    "# do_batches = True\n",
    "# batch_size = 1024\n",
    "# indices = []\n",
    "\n",
    "# # for i in range(30000):\n",
    "# for i in range(config['num_epochs']):\n",
    "#     if do_batches:\n",
    "#         # shuffle the batches\n",
    "#         if i%10 == 0:\n",
    "#             indices = torch.randperm(len(x))\n",
    "#             x_shuffled = x[indices]\n",
    "#             y_shuffled = y[indices]\n",
    "#         # y_shuffled = sample_values[indices]\n",
    "#         if do_grad:\n",
    "#             mgh_shuffled = mgh[indices]\n",
    "#         if do_grad:\n",
    "#             batch1 = x_shuffled[:512], y_shuffled[:512], mgh_shuffled[:512]\n",
    "#             batch2 = x_shuffled[512:], y_shuffled[512:], mgh_shuffled[512:]\n",
    "#         else:\n",
    "#             batch1 = x_shuffled[:512], y_shuffled[:512]\n",
    "#             batch2 = x_shuffled[512:], y_shuffled[512:]\n",
    "#         batch1_loss = t.train_batch(*batch1)\n",
    "#         batch2_loss = t.train_batch(*batch2)\n",
    "#     else:\n",
    "#         if do_grad:\n",
    "#             full_batch = x,y,mgh\n",
    "#         else:\n",
    "#             full_batch = x, y\n",
    "#         t.train_batch(*full_batch)\n",
    "    \n",
    "        \n",
    "#     if i % 100 == 0:\n",
    "#         with torch.no_grad():\n",
    "#             print('epoch: ', i)\n",
    "#             if do_grad:\n",
    "#                 print('loss is ', t.loss_fn(net(x).squeeze(), y, mgh).item())\n",
    "#             else:\n",
    "#                 print('loss is ', t.loss_fn(net(x).squeeze(), y).item())\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291.7323913574219\n"
     ]
    }
   ],
   "source": [
    "Z = (mess * mg).sum_all_entries()\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.195556640625"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get partition function estimate\n",
    "# Z_linear_test = 316.2219543457031\n",
    "mess_hat = FastFactor.nn_to_FastFactor(idx, fastgm, data_preprocessor, net=net, device=device)\n",
    "# mess_hat = FastFactor.nn_to_FastFactor(idx, fastgm, None, net=net, device=device)\n",
    "(mess_hat*mg).sum_all_entries() - Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0265, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x).squeeze()[553]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0457, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[553]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(250.0704, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mess.tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.188446044921875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4032, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x).squeeze()[713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.9636, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(net(x).squeeze() - y).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0457, device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x).squeeze()[492]\n",
    "y[492]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(492, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax((net(x).squeeze() - y) * mgh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0248, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((net(x).squeeze() - y) * mgh)[492]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304.7890930175781"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre permutation elim indices:  [4]\n",
      "pre permutation tensor_assignment_indices:  [0, 1, 2, 3]\n",
      "permutation:  (0, 1, 2, 3, 4)\n",
      "assignment_indices are  [0, 1, 2, 4]\n",
      "projected_assignments are tensor([[0, 0, 0, 0],\n",
      "        [1, 2, 3, 5]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.rand(2,3,4,6,7)\n",
    "assignments = torch.IntTensor([[0,0,0,0,0],[1,2,3,4,5]])\n",
    "labels = [1,2,3,5,6] # of factor\n",
    "scope = [1,2,3,4,5] # of message\n",
    "elim_vars = [6]\n",
    "elim_indices = [i for i, idx in enumerate(labels) if idx in elim_vars]\n",
    "print('pre permutation elim indices: ', elim_indices)\n",
    "assignment_indices = [i for i, idx in enumerate(scope) if idx in labels]\n",
    "tensor_assignment_indices = [i for i, idx in enumerate(labels) if idx not in elim_vars]\n",
    "print('pre permutation tensor_assignment_indices: ', tensor_assignment_indices)\n",
    "permutation = (*tensor_assignment_indices, *elim_indices)\n",
    "print('permutation: ', permutation)\n",
    "tensor = tensor.permute(permutation)\n",
    "# reordered labels\n",
    "labels = [labels[i] for i in permutation]\n",
    "# for loop through the columns of the tensor, so yes, this is efficient\n",
    "# assignment_indices = [i for i, idx in enumerate(labels) if idx in scope]\n",
    "print('assignment_indices are ', assignment_indices)\n",
    "projected_assignments = assignments[:,assignment_indices]\n",
    "print('projected_assignments are', projected_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [0, 2],\n",
       "        [0, 3],\n",
       "        [0, 5]], dtype=torch.int32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projected_assignments.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [0, 2],\n",
       "        [0, 3],\n",
       "        [0, 5]], dtype=torch.int32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape\n",
    "projected_assignments.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5187, 0.2667],\n",
       "        [0.0743, 0.7428],\n",
       "        [0.1504, 0.0098],\n",
       "        [0.0135, 0.9487],\n",
       "        [0.9570, 0.0108],\n",
       "        [0.4947, 0.4307],\n",
       "        [0.6047, 0.6806]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[:,[0,1],[0,2],[0,3],[0,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mt2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprojected_assignments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "t2 = torch.rand(2,3,4,6)\n",
    "t2[projected_assignments.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [indices[:, dim].unsqueeze(-1) for dim in range(indices.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0],\n",
       "         [1]]),\n",
       " tensor([[0],\n",
       "         [2]]),\n",
       " tensor([[0],\n",
       "         [3]]),\n",
       " tensor([[0],\n",
       "         [4]])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "view() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (torch.dtype dtype)\n * (tuple of ints size)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: view() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (torch.dtype dtype)\n * (tuple of ints size)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(2,3,4,5)\n",
    "a.view(torch.tensor(a.shape[:2]), torch.prod(torch.tensor(a.shape[2:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(int(dim) for dim in a.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6675, 0.2818, 0.5232],\n",
       "          [0.7850, 0.4291, 0.4799],\n",
       "          [0.9067, 0.4759, 0.1384]],\n",
       "\n",
       "         [[0.0836, 0.9033, 0.0685],\n",
       "          [0.5516, 0.6661, 0.5801],\n",
       "          [0.3347, 0.4222, 0.7964]],\n",
       "\n",
       "         [[0.4056, 0.7190, 0.1852],\n",
       "          [0.3702, 0.8057, 0.1589],\n",
       "          [0.5209, 0.2540, 0.4539]]],\n",
       "\n",
       "\n",
       "        [[[0.2109, 0.1926, 0.6154],\n",
       "          [0.2832, 0.4957, 0.8275],\n",
       "          [0.7963, 0.1209, 0.8235]],\n",
       "\n",
       "         [[0.4514, 0.0938, 0.6211],\n",
       "          [0.2247, 0.4675, 0.0014],\n",
       "          [0.1073, 0.7820, 0.9860]],\n",
       "\n",
       "         [[0.1778, 0.3909, 0.0477],\n",
       "          [0.4185, 0.5575, 0.8668],\n",
       "          [0.6914, 0.4952, 0.5116]]],\n",
       "\n",
       "\n",
       "        [[[0.2281, 0.4498, 0.6238],\n",
       "          [0.4719, 0.2846, 0.0985],\n",
       "          [0.3959, 0.9456, 0.0308]],\n",
       "\n",
       "         [[0.6465, 0.4795, 0.9703],\n",
       "          [0.8482, 0.4505, 0.3884],\n",
       "          [0.7556, 0.3110, 0.8642]],\n",
       "\n",
       "         [[0.6489, 0.6739, 0.8286],\n",
       "          [0.8991, 0.5311, 0.7211],\n",
       "          [0.0215, 0.3400, 0.5150]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elim_vars = [6,7]\n",
    "tensor=torch.rand(3,3,3,3)\n",
    "tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.6675, 0.2818, 0.5232]],\n",
       "\n",
       "          [[0.7850, 0.4291, 0.4799]],\n",
       "\n",
       "          [[0.9067, 0.4759, 0.1384]]],\n",
       "\n",
       "\n",
       "         [[[0.0836, 0.9033, 0.0685]],\n",
       "\n",
       "          [[0.5516, 0.6661, 0.5801]],\n",
       "\n",
       "          [[0.3347, 0.4222, 0.7964]]],\n",
       "\n",
       "\n",
       "         [[[0.4056, 0.7190, 0.1852]],\n",
       "\n",
       "          [[0.3702, 0.8057, 0.1589]],\n",
       "\n",
       "          [[0.5209, 0.2540, 0.4539]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0.2109, 0.1926, 0.6154]],\n",
       "\n",
       "          [[0.2832, 0.4957, 0.8275]],\n",
       "\n",
       "          [[0.7963, 0.1209, 0.8235]]],\n",
       "\n",
       "\n",
       "         [[[0.4514, 0.0938, 0.6211]],\n",
       "\n",
       "          [[0.2247, 0.4675, 0.0014]],\n",
       "\n",
       "          [[0.1073, 0.7820, 0.9860]]],\n",
       "\n",
       "\n",
       "         [[[0.1778, 0.3909, 0.0477]],\n",
       "\n",
       "          [[0.4185, 0.5575, 0.8668]],\n",
       "\n",
       "          [[0.6914, 0.4952, 0.5116]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0.2281, 0.4498, 0.6238]],\n",
       "\n",
       "          [[0.4719, 0.2846, 0.0985]],\n",
       "\n",
       "          [[0.3959, 0.9456, 0.0308]]],\n",
       "\n",
       "\n",
       "         [[[0.6465, 0.4795, 0.9703]],\n",
       "\n",
       "          [[0.8482, 0.4505, 0.3884]],\n",
       "\n",
       "          [[0.7556, 0.3110, 0.8642]]],\n",
       "\n",
       "\n",
       "         [[[0.6489, 0.6739, 0.8286]],\n",
       "\n",
       "          [[0.8991, 0.5311, 0.7211]],\n",
       "\n",
       "          [[0.0215, 0.3400, 0.5150]]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.reshape(3,3,3,1,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a\n",
    "b = b.permute(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8012, 0.6901, 0.9071],\n",
       "        [0.4665, 0.9279, 0.7756],\n",
       "        [0.4795, 0.9028, 0.7312]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(5)\n",
    "assert([a[i]<a[i+1] for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(all([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
